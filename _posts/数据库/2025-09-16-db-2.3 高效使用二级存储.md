---
layout: post
title:  "2.3 高效使用二级存储"
category: "数据库"
order: "3"
math: true
---

大多数算法都假定数据是在主存中的，可以用相同的时间读取任意数据项。这种计算模型被称为随机访问模型（RAM）。然而，当实现数据库系统时，我们必须假设数据无法全部存放在主存中，因此必须考虑二级存储，甚至是三级存储的使用。对同一个问题而言，处理这种大数据的最好的算法通常与处理主存中的数据的最好的算法并不相同。

这一节中，我们会主要考虑主存与二级存储的交互。特别是，我们在设计算法时会优先考虑限制磁盘访问次数，即使这个算法在主存中的行为可能并不是最优的。这种原则也可以应用到其他存储层级。例如对于主存与缓存的交互来说，如果我们能将算法设计成，将高频访问的数据加载到缓存中，那么内存数据上的算法就可以优化。类似的，如果算法设计二级存储与三级存储之间的数据交换，那么也是要尽量少的减少数据交换的次数。

### 2.3.1 计算的 I/O 模型

我们来考虑一个简单场景：数据库系统要服务一系列查询（query）和修改（modification）请求。假设计算机只有一个处理器，一个磁盘控制器，一个磁盘。数据库本身无法存放在主存中。数据库的关键部件或许可以被加载到主存中，但是基本上每一个用户请求都需要访问/写入磁盘。

我们对硬件性能做典型的假设：块大小为 4 KB，读写一个块的时间平均是 15 毫秒。由于用户数量很多，而且每个 用户都会频繁访问磁盘，因此磁盘控制器就需要维护一个请求队列。我们假设它是先到先服务的。这种策略的一个结果就是，请求将是随机的。即使每个用户都在访问一些连续的数据，比如多次访问存放在同一个块中的关系表，但磁盘控制器接到的请求位置不具有连续性。稍后我们会讨论提升这一系统性能的不同方法。

根据这一规则，我们可以定义计算的 I/O 模型：

- **I/O 开销主导**：如果需要在磁盘和主存之间移动数据，所需的开销会远远高于在主存中处理数据的开销。因此，读写磁盘块的数量就是对算法开销的一个很好的近似。优化算法的主要手段也就是减少磁盘块的读写数量。

例如，在读写一个块所需要的 15 毫秒内，现代微处理器可以执行上百万条指令。在主存中查找一个关键字，即使使用最笨的线性扫描，可能也只需要上千条指令。主存操作的开销相比于读写磁盘还不足 1%，所以可以被放心地忽略掉。

### 2.3.2 在二级存储中排序

考虑要对超出主存容量的数据进行排序的问题。假设我们有一个巨大的关系表 $R$，包含一千万个元组。每个元组都表示了一条记录，包含多个属性，其中包含排序码，以及可以作为唯一标识的关键码。我们的目标是将所有记录按排序码升序排列。

为了简单起见，我们假定所有排序码都不重复，以及每一条记录的长度是固定的 100 字节。这样，全部记录需要占据 1 GB 空间，而可用的内存空间假设是 50 MB。

磁盘块大小是 4096 B，所以我们可以将 40 条记录放在一个块中，剩余的 96 字节可以闲置，也可以用来记录一些必要的信息。全部的记录会占据 250,000 个块，而主存最多同时容纳 12,800 个块。

我们知道在主存中进行排序的高效算法，但显然问题在于，我们只能一次性对一小部分数据进行排序。一个想法或许是，对一个指针序列进行排序，每个指针都指向它们在二级存储中的数据项。但这是一个很坏的想法，因为它使用了过多的磁盘读写，而我们想要减少磁盘读写的数量。

### 2.3.3 归并排序

假定我们都熟悉内存排序的归并排序算法（Merge Sort），它的复杂度是 $O(n\log n)$ 的。

### 2.3.4 两阶段多路归并排序

我们会使用一种归并排序的变体：两阶段多路归并排序，来解决上述问题。这也是许多数据库应用中会使用的算法。它所说的两阶段指的是：

1. 对大小恰好能装进主存的数据块进行排序，从而形成一系列有序的子序列。

2. 将所有有序子序列归并为一个有序序列

我们的第一个观察是，由于数据在二级存储中，所以递归算法的递归基础不应该是一个或几个记录，否则就会导致大量 I/O 次数。递归基础应该是一次性对主存大小的数据块进行排序。具体来说，我们会重复以下这个过程：

1. 用待排序数据填充满主存

2. 在主存中对数据排序

3. 将排好序的数据从主存写回到二级存储块中，形成一个有序子序列

第一阶段结束后，原关系表中所有的记录都会被读取和写回一遍，并成为有序子序列的一部分。

在上面的例子中，我们知道 250,000 中的 12,800 个块能够装满主存，所以我们需要重复 20 遍上述过程。最后一次形成的子序列不满 12,800 个块，它只有 6,800 个块。

这一过程花费多长时间？我们要读写 250,000 个块，也就是共 500,000 次 I/O。我们假设块在磁盘上的位置是随机的（2.4 节中我们会讨论如何打破这个假设，从而改进性能），这样，花费的时间就是 7,500 秒，接近 2.5 小时。我们可以认为，CPU 指令的运行时间远远小于这一数字。

现在，我们来考虑如何将有序子序列合并起来。我们可以两两合并，对于 $n$ 个子序列，这需要 $2log_2 n$ 次 I/O。

更好的方法是，我们将每个待排序子序列的第一个块都读进主存中。当然，如果数据量特别大，形成的子序列数量特别多，我们甚至也做不到这一点，我们会在 2.3.5 中讨论这个问题。但就上面的例子而言，我们可以将 20 个块全部加载到内存中。

我们还会使用一个缓冲输出块，用来存放完成排序将要输出的记录。这个块被初始化为空，然后进行如下操作：

1. 在主存中寻找各子序列的最小的键值。这一过程是在主存中进行的，使用线性搜索已经足够了。但如果我们想要改进一下的话，可以使用优先队列，以对数复杂度来获得最小的记录。

2. 将最小的记录移动到输出缓冲块的第一个可用位置。

3. 如果输出缓冲快满了，就将它写回磁盘，并重新初始化输出缓冲块。

4. 当一个子序列的块的记录都已经加入输出缓冲区后，就可以读取这个子序列的下一个块。如果没有下一个块，那么保持这个块为空，接下来也无需处理这个块了。

在第二阶段，由于我们无法预测输入块什么时候被耗尽，块是以无法预测的顺序读取的，并且，也容易发现每个块同样各进行了一次读写，这样就又花费了 7,500 秒。

### 2.3.5 将多路归并扩展到更大的关系表

上面提到，关系表可能特别大，以至于无法将每个子序列的一个块加载到内存中。我们假设：

1. 块大小为 $B$ 字节

2. 主存可用作缓冲的空间为 $M$ 字节

3. 一条记录占用 $R$ 字节

那么主存中可以容纳 $M/B$ 个块作为输入缓冲。第二阶段中，$M/B$ 中的一个块被用作输出缓冲，其他 $M/B - 1$ 块都被用作输入缓冲。这意味着在第一阶段中，我们最多只能生成这么多个子序列。而第一阶段中，我们一次性最多对 $M/R$ 条记录进行排序。所以，用这种方式最多能处理的记录数是 $(M/R)(M/B - 1)$，近似为 $M^2/RB$。

用上面的例子，这一值是 $M^2/RB = (50M)^2 / (4096 * 100) = 6.1e8$，占据大约 610 GB 空间。而这一容量用我们假设的磁盘设备是远远无法存储的，可能需要动用三级存储，并在三级存储和二级存储之间使用类似的多路归并排序方法。

如果我们需要排序个更多记录，我们可以加入第三个阶段。我们知道在第二阶段中，进行一次多路归并排序允许我们将大约 M/B 个子序列合并为一个子序列。我们会将第二阶段重复多次，并在第三阶段，我们会合并第二阶段形成的各个子序列。

这样，我们总共能处理的子序列数量就大致是 $M^2/B^2$，也就是$M^3/B^2R$ 条记录，这将占据 7,500 PB 空间。 

