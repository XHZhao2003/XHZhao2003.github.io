---
layout: post
title: "摊还分析"
category: "数据结构与算法"
order: "3"
math: true
---

### 时间复杂度分析

基本的时间复杂度分析技术是，考察待分析算法或数据结构操作中的基本操作次数，然后考察操作次数的总执行次数，从而得到算法的时间复杂度。

在这个过程中，很常见的情况是，基本操作的次数取决于算法的输入，或者数据结构的当前状态，这一差异可能导致得到不同的时间复杂度。例如，某个操作的最低时间复杂度可能是 $O(1)$ 的，而最高时间复杂度可能是 $O(n)$ 的。

### 摊还分析

摊还分析的出发点是，对于数据结构的一个操作来说，尽管每次操作代价的复杂度可能是有差异的，但是很可能一次代价较高的操作之后，后续的一系列操作都是代价较低的。这样一来，一个操作序列的总代价并没有特别高，均摊到每次操作上的**平均复杂度**也没有特别高。

另一个相似的情况是，数据结构有不同的操作 A 和 B，A 操作的代价的复杂度是较高的，B 操作代价的复杂度是较低的。注意，复杂度高不意味着实际代价总是较高。比如，只有在进行大量 B 操作之后，下一次 A 操作的实际代价才会达到比较高的水平。这种情况下，我们可以假想每一次 B 操作替 A 操作承担了一些代价。这样一来，A 操作的**摊还代价**的复杂度就大大降低了。

总结来说，由于数据结构的本身机制，较早的操作的代价和较晚的操作的代价可能相互影响；一种操作对另一种操作的代价也可能产生影响。如果仅单独考虑每次操作的代价，就会忽略这些影响。因此，摊还代价分析的对象通常是一个操作序列，得到的结果是其中每一类的操作摊还代价复杂度。

摊还分析考虑的是最差情况，通过找到数据结构本身的机制是如何限制最差情况的代价的，来进行分析。

摊还分析技术主要有三种：聚合分析，核方法，势函数方法。下面分别用一个例子来解释这三种技术。

### 聚合分析

聚合分析计算一个操作序列的总代价，从而得到每个操作平均代价。操作序列中可能包含不同类型的操作，但聚合分析为不同操作计算的平均代价总是相同的。

考虑一个支持动态扩展的顺序表。为了支持插入任意多的元素，动态扩展技术首先分配一个固定大小的空间，在其中超过 1/2 的空间被占据后，就新分配一块大小为原空间 2 倍的空间，并将原空间的数据拷贝的新的空间。假设初始时顺表表的容量为 0。

这样，顺序表的 Insert 操作在最好情况下的代价是 $O(1)$ 的，而在最坏情况下的代价是 $O(n)$ 的。如果执行 $n$ 次，最坏的总代价就是 $O(n^2)$ 的。

应用聚合分析，我们应该注意到动态扩展操作很少发生：只有当表中元素的操作恰好为 $2^i-1$ 时，才会动态扩展。进行 $n$ 次插入操作的总代价就是
$$
C_{\text{insert}} + C_{\text{expand}}=n+\sum_{i=0}^{\lfloor \log n \rfloor}2^i <n+2n=O(n)
$$
所以，总的代价是 $O(n)$ 的，每一次插入操作的均摊代价是 $O(1)$ 的。这就表明，动态扩展方案尽管需要多次拷贝数据，但平均而言每次插入的代价仍然是 $O(1)$ 的。

### 核方法（accounting method）

首先做一点说明，accounting method 被翻译成核方法，几乎同时失去了信达雅。我会将它简单地翻译成账户方法。Anyway，我们还是用核方法来指代这种技术。

用核方法进行摊还分析时，我们为每一类操作赋予一个摊还代价。同一类操作的摊还代价是相同的，不同类操作可以具有不同的摊还代价。这样，我们扩展了聚合分析方法，因为我们不仅能得到一组操作的平均代价，还能区分不同种类操作的不同代价。

当然，摊还代价的具体值是我们（通过分析或者猜测）假想出来的，实际代价也不会等于摊还代价。当一个操作的实际代价小于摊还代价时，我们就在账户上累计了一些余额（credit）；而当一个操作的实际代价超过摊还代价时，我们就需要花费账户余额。对于一个具体问题，我们的目标是定义合适的摊还代价，使得在操作序列的任意时刻，账户上的余额总是非负的。这样，使用这个摊还代价来计算操作系列的总代价，得到的总是实际代价的一个上界。

考虑一个数组实现的二进制计数器，具有 $k$ 个取值 0 或 1 的位，左侧是最高位，右侧是最低位，能够表示 $[0, 2^k-1]$ 内的所有整数。假设计数器的初始值是 0。考虑这个计数器的 Increment 操作，也就是将计数器的值在 $\bmod 2^k$ 的意义下加一。Increment 操作的实现方式就是反转计数器中的若干位，我们可以用写入的次数来代表操作的实际代价。我们还让计数器支持置位操作 Set，也就是将指定下标的位写入为 1。现在，考虑这个计数器从初始值 0 开始的一个由 $n$ 个 Increment 或 Other 操作组成的操作序列。

使用粗略的分析，我们知道每次 Increment 的最大代价是 $O(k)$，那么 $n$ 次 Increment 的代价就是 $O(kn)$，$n$ 次 Other 操作的代价是 $O(n)$。

使用核方法，我们选择定义 Increment，Set 操作的摊还代价都是 2。这里两个摊还代价是相等的，但是从下面的论证过程中可以看出来这只是一个巧合。我们先说明 Increment，Set 的具体做法是：从最低位开始，寻找连续的值为 1 的位，将其值复位为 0；直到第一个值为 0 的位，将其值写入位 1。如果不存在值为 0 的位，则无需写入。 Set 操作简单地把指定位写入为 1。

我们是这样看待账户余额的：计数器中每存在一个值为 1 的位，就有一单位余额与此对应。我们归纳说明这一点。初始时，没有这样的位也没有任何余额。当我们调用 Set 方法时，Set 本身的实际代价是 1，因为它只写入了一次；所以它就为这个位累计了一单位余额。当我们调用 Increment 方法时，如果计数器没有溢出的话，它就会写入一个 1，产生一单位实际代价。摊还代价中的另一个单位也会记录为余额。当然，它还会将一系列值为 1 的位复位，产生至多达到 $k$ 的实际代价。我们将使用账户余额来支付这些代价。每一个值位 1 的位都储存了一个余额，所以我们的账户余额总是足够的；而且，随着余额被消耗，对应位上的 1 也变成了 0。

这样就足以说明账户余额总是非负的，Increment 和 Set 操作的摊销代价都是 2。

### 势能法（势函数法）

势能法的本质与核方法相同，所谓势函数就是账户余额。区别主要在于，势函数在定义上是数据结构的本身状态的函数，而不是由摊还代价和实际代价定义的。然后，通过势函数，我们再推导出每个操作的摊销代价：等于实际代价加上势函数的变化量。整个操作序列的摊还代价就是实际代价加上势函数在全过程的变化量。我们要求势函数的累计变化量总是正的，从而总摊还代价就是总实际代价的上界。

对于上述计数器的例子，势函数将定义为计数器中 1 的个数。一次 Set 操作的实际代价是 1，可能使势函数增加 0 或 1，因此摊还代价不超过 2。一次 Increment 操作的实际代价取决于它复位的位数 $p\in[0, k]$ 和置位的位数 $q\in [0, 1]$，实际代价是 $p+q$，势能变化是 $q-p$，因此摊还代价是 $2q$，总是不超过 2。

算法导论提供了一个习题：考虑一般的二叉堆的 Insert 和 Extract-Min 操作的复杂度都是 $O(\log n)$ 的。但是可以设计一个势函数，使得 Insert 的摊还代价是 $O(\log n)$，而 Extract-Min 的摊还代价是 $O(1)$。

为了将 Extract-Min 的代价摊销到 Insert 操作上，我们注意到 Extract-Min 的代价来自于，将堆中的最后一个元素置入堆顶，然后进行 Sift-Down 调整。同时，我们还需要注意到，Extract-Min 的操作次数永远不会超过 Insert 次数。（其实当然可以超过，只不过超过的部分就报错返回，不会产生我们关心的代价） 

自然的想法是，每个元素被 Insert 时，就以某种方式预先支付将来被删除后 Extract-Min 的代价。这个代价显然是二叉树的高度，所以预先支付的数量也应该是二叉树高度。我们肯定会注意到，一个元素插入时树的高度是 $h$，不意味着删除时树的高度也是 $h$。所以，每个元素支付的不是自己删除时的代价。如果删除一个元素时树的高度是 $h'$，就意味着树中一定存在一个元素，预先支付了 $h'$ 的代价。

所以，势函数被定义为 

$$
f(H)=\sum_{i=1}^nh_i
$$

$H, i$ 分别表示二叉树和二叉树中的结点，$h_i$ 表示结点的高度。这样，Insert 操作的摊还代价是实际代价（$O(\log n)$）加上势能变化，也就是新插入结点的高度，同样是 $O(\log n)$，因此摊还代价就是 $O(\log n)$ 的。对于 Extract-Min 操作，势函数的减小量是删除前的二叉树的高度。用结点的值写入次数代表实际代价，实际代价不超过删除后的树高度 + 1。因此，Extract-Min 操作的摊还代价就是 $O(1)$ 的。